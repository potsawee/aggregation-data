{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09266f75-e316-4bfa-aa81-af66a40f736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2b0fb1-8dbc-4a53-a231-797632fc3e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lmsys-chatbot-arena/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a554a4f-def8-4c96-8e03-76849c9a4ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>[\"I have three oranges today, I ate an orange ...</td>\n",
       "      <td>[\"You have two oranges today.\"]</td>\n",
       "      <td>[\"You still have three oranges. Eating an oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>[\"You are a mediator in a heated political deb...</td>\n",
       "      <td>[\"Thank you for sharing the details of the sit...</td>\n",
       "      <td>[\"Mr Reddy and Ms Blue both have valid points ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>[\"How to initialize the classification head wh...</td>\n",
       "      <td>[\"When you want to initialize the classificati...</td>\n",
       "      <td>[\"To initialize the classification head when p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   136060  [\"I have three oranges today, I ate an orange ...   \n",
       "1   211333  [\"You are a mediator in a heated political deb...   \n",
       "2  1233961  [\"How to initialize the classification head wh...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0                    [\"You have two oranges today.\"]   \n",
       "1  [\"Thank you for sharing the details of the sit...   \n",
       "2  [\"When you want to initialize the classificati...   \n",
       "\n",
       "                                          response_b  \n",
       "0  [\"You still have three oranges. Eating an oran...  \n",
       "1  [\"Mr Reddy and Ms Blue both have valid points ...  \n",
       "2  [\"To initialize the classification head when p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2de8b095-da10-427a-9a2e-01a635f86734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lmsys-chatbot-arena/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3afc8c2-223e-476a-99bf-575dcebc0445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96401</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>mistral-7b-instruct</td>\n",
       "      <td>[\"How can I create a test set for a very rare ...</td>\n",
       "      <td>[\"Creating a test set for a very rare category...</td>\n",
       "      <td>[\"When building a classifier for a very rare c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198779</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-3.5-turbo-0314</td>\n",
       "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
       "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
       "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57472</th>\n",
       "      <td>4294656694</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>[\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...</td>\n",
       "      <td>[\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...</td>\n",
       "      <td>[\"Here is how that mnemonic represents the dig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57473</th>\n",
       "      <td>4294692063</td>\n",
       "      <td>claude-2.0</td>\n",
       "      <td>llama-2-13b-chat</td>\n",
       "      <td>[\"In python, implement a naive Bayes with gaus...</td>\n",
       "      <td>[\"Here is an implementation of a naive Bayes c...</td>\n",
       "      <td>[\"Sure! Here's an implementation of a naive Ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57474</th>\n",
       "      <td>4294710549</td>\n",
       "      <td>claude-1</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>[\"is it unethical to work on building weapons?...</td>\n",
       "      <td>[\"Working on weapons technology raises some et...</td>\n",
       "      <td>[\"It depends on the context. Weapons can be us...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57475</th>\n",
       "      <td>4294899228</td>\n",
       "      <td>palm-2</td>\n",
       "      <td>tulu-2-dpo-70b</td>\n",
       "      <td>[\"If a bait contains 0,0025% bromadiolon then ...</td>\n",
       "      <td>[\"Bromadiolone is a rodenticide which is most ...</td>\n",
       "      <td>[\"As an AI language model, I do not promote or...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57476</th>\n",
       "      <td>4294947231</td>\n",
       "      <td>gemini-pro-dev-api</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>[\"three kids eat three apples in three days, h...</td>\n",
       "      <td>[\"27 apples\"]</td>\n",
       "      <td>[\"If three kids eat three apples in three days...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57477 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             model_a              model_b  \\\n",
       "0           30192  gpt-4-1106-preview           gpt-4-0613   \n",
       "1           53567           koala-13b           gpt-4-0613   \n",
       "2           65089  gpt-3.5-turbo-0613       mistral-medium   \n",
       "3           96401    llama-2-13b-chat  mistral-7b-instruct   \n",
       "4          198779           koala-13b   gpt-3.5-turbo-0314   \n",
       "...           ...                 ...                  ...   \n",
       "57472  4294656694          gpt-4-0613             claude-1   \n",
       "57473  4294692063          claude-2.0     llama-2-13b-chat   \n",
       "57474  4294710549            claude-1           alpaca-13b   \n",
       "57475  4294899228              palm-2       tulu-2-dpo-70b   \n",
       "57476  4294947231  gemini-pro-dev-api   gpt-4-1106-preview   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      [\"Is it morally right to try to have a certain...   \n",
       "1      [\"What is the difference between marriage lice...   \n",
       "2      [\"explain function calling. how would you call...   \n",
       "3      [\"How can I create a test set for a very rare ...   \n",
       "4      [\"What is the best way to travel from Tel-Aviv...   \n",
       "...                                                  ...   \n",
       "57472  [\"A simple mnemonic for \\u03c0:\\n\\\"How I wish ...   \n",
       "57473  [\"In python, implement a naive Bayes with gaus...   \n",
       "57474  [\"is it unethical to work on building weapons?...   \n",
       "57475  [\"If a bait contains 0,0025% bromadiolon then ...   \n",
       "57476  [\"three kids eat three apples in three days, h...   \n",
       "\n",
       "                                              response_a  \\\n",
       "0      [\"The question of whether it is morally right ...   \n",
       "1      [\"A marriage license is a legal document that ...   \n",
       "2      [\"Function calling is the process of invoking ...   \n",
       "3      [\"Creating a test set for a very rare category...   \n",
       "4      [\"The best way to travel from Tel Aviv to Jeru...   \n",
       "...                                                  ...   \n",
       "57472  [\"Sure, let's break it down:\\n\\n1. \\\"How\\\" has...   \n",
       "57473  [\"Here is an implementation of a naive Bayes c...   \n",
       "57474  [\"Working on weapons technology raises some et...   \n",
       "57475  [\"Bromadiolone is a rodenticide which is most ...   \n",
       "57476                                      [\"27 apples\"]   \n",
       "\n",
       "                                              response_b  winner_model_a  \\\n",
       "0      [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1      [\"A marriage license and a marriage certificat...               0   \n",
       "2      [\"Function calling is the process of invoking ...               0   \n",
       "3      [\"When building a classifier for a very rare c...               1   \n",
       "4      [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
       "...                                                  ...             ...   \n",
       "57472  [\"Here is how that mnemonic represents the dig...               1   \n",
       "57473  [\"Sure! Here's an implementation of a naive Ba...               1   \n",
       "57474  [\"It depends on the context. Weapons can be us...               1   \n",
       "57475  [\"As an AI language model, I do not promote or...               0   \n",
       "57476  [\"If three kids eat three apples in three days...               1   \n",
       "\n",
       "       winner_model_b  winner_tie  \n",
       "0                   0           0  \n",
       "1                   1           0  \n",
       "2                   0           1  \n",
       "3                   0           0  \n",
       "4                   1           0  \n",
       "...               ...         ...  \n",
       "57472               0           0  \n",
       "57473               0           0  \n",
       "57474               0           0  \n",
       "57475               1           0  \n",
       "57476               0           0  \n",
       "\n",
       "[57477 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cd792f1-ea9b-4c31-bab5-e51f02071a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bde3c32-c8c2-48ac-b655-80d9a56d9843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 57477/57477 [00:03<00:00, 14724.55it/s]\n"
     ]
    }
   ],
   "source": [
    "counter = {1: 0, 2: 0, 3: 0}\n",
    "one_turn = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    x = df.iloc[i]\n",
    "    question = json.loads(x['prompt'])\n",
    "    answer_a = json.loads(x['response_a'])\n",
    "    answer_b = json.loads(x['response_b'])\n",
    "    assert len(question) == len(answer_a)\n",
    "    assert len(answer_a) == len(answer_b)\n",
    "    n = len(question)\n",
    "    if n == 1 or n == 2:\n",
    "        counter[n] += 1\n",
    "    else:\n",
    "        counter[3] += 1\n",
    "    if n == 1:\n",
    "        one_turn.append({\n",
    "            'id': int(x['id']),\n",
    "            'model_a': x['model_a'],\n",
    "            'model_b': x['model_b'],\n",
    "            'winner_model_a': int(x['winner_model_a']),\n",
    "            'winner_model_b': int(x['winner_model_b']),\n",
    "            'winner_tie': int(x['winner_tie']),\n",
    "            'question': question[0],\n",
    "            'answer_a': answer_a[0],\n",
    "            'answer_b': answer_b[0],\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b815430-02e2-4542-8b62-3273eb009dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lmsys-chatbot-arena/train.single-turn.json\", \"w\") as f:\n",
    "    json.dump(one_turn, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d3b28bc3-32d1-4b89-8855-76d58593b2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49938"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63b9867b-06b2-4d09-b342-a0d02a2a9763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 49938, 2: 4673, 3: 2866}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "986370ab-c285-4697-a441-4ac198164d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is it morally right to try to have a certain percentage of females on managerial positions?',\n",
       " 'OK, does pineapple belong on a pizza? Relax and give me fun answer.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4ca5eb3-eff1-422d-8f66-d55837f9e660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "351b2252-7ff1-4af3-9e63-364adedc1546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "379f91e0-212a-4f9f-9ec3-2a1c72d60eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['winner_model_a']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bf50fc-8d46-4fae-af21-9f86f6057d24",
   "metadata": {},
   "source": [
    "# Sainity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4cbd1aba-9ef7-4850-949c-6db62f2fb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"lmsys-chatbot-arena/train.single-turn.json\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f77b0c64-9a3e-44d3-ac3d-1419929d09a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 65089,\n",
       " 'model_a': 'gpt-3.5-turbo-0613',\n",
       " 'model_b': 'mistral-medium',\n",
       " 'winner_model_a': 0,\n",
       " 'winner_model_b': 0,\n",
       " 'winner_tie': 1,\n",
       " 'question': 'explain function calling. how would you call a function?',\n",
       " 'answer_a': 'Function calling is the process of invoking or executing a function in a programming language. To call a function, you need to use the function\\'s name followed by parentheses \"()\". Within the parentheses, you can pass arguments if the function requires any.\\n\\nHere is an example of how to call a function in Python:\\n\\n```python\\n# Define a function\\ndef greet(name):\\n    print(\"Hello, \" + name + \"!\")\\n\\n# Call the function\\ngreet(\"John\")\\n```\\n\\nIn this example, the function \"greet\" is defined with a single parameter \"name\" which is used to print a greeting message. To call the function and pass an argument, we write \"greet(\"John\")\". This will execute the function and print \"Hello, John!\".\\n\\nIt is important to note that the function should be defined before calling it in most programming languages, as the interpreter needs to know about the function\\'s existence before it can be called.',\n",
       " 'answer_b': 'Function calling is the process of invoking a function in a program. A function is a block of code that performs a specific task and can be reused multiple times in a program. Functions help to organize and modularize code, making it more readable and maintainable.\\n\\nTo call a function, you simply write the name of the function followed by parentheses () containing any arguments or parameters that the function requires. Here\\'s an example:\\n```\\nfunction greet(name) {\\n  console.log(\"Hello, \" + name);\\n}\\n\\n// Call the greet function and pass in the argument \"Alice\"\\ngreet(\"Alice\");\\n```\\nIn the example above, the function `greet` takes one parameter, `name`, which is used inside the function to print a greeting message. To call the function, we write the name of the function (`greet`) followed by parentheses containing the argument `\"Alice\"`. When the function is called, the argument `\"Alice\"` is passed to the function, where it is assigned to the `name` parameter. The function then uses the `name` parameter to print the greeting message `\"Hello, Alice\"`.\\n\\nFunctions can also return values, which can be assigned to variables or used in expressions. For example:\\n```\\nfunction addNumbers(a, b) {\\n  return a + b;\\n}\\n\\n// Call the addNumbers function and assign the result to the variable sum\\nvar sum = addNumbers(3, 5);\\nconsole.log(sum); // Output: 8\\n```\\nIn the example above, the function `addNumbers` takes two parameters, `a` and `b`, adds them together, and returns the result. To call the function, we write the name of the function (`addNumbers`) followed by parentheses containing the arguments `3` and `5`. The function calculates the sum of the two arguments (`3 + 5 = 8`) and returns the result (`8`). We then assign the result to the variable `sum` and print it to the console.'}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75238ec2-f2b4-4d62-8c18-aa0e43fdafe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "winners = {'A': 0, 'B': 0, 'tie': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e74b78f9-ec02-4bf8-8af2-848dd2101530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49938/49938 [00:00<00:00, 1505452.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(data))):\n",
    "    x = data[i]\n",
    "    assert x['winner_model_a'] + x['winner_model_b'] + x['winner_tie'] == 1\n",
    "    if x['winner_model_a'] == 1:\n",
    "        winner_gt = \"A\"\n",
    "    elif x['winner_model_b'] == 1:\n",
    "        winner_gt = \"B\"\n",
    "    elif x['winner_tie'] == 1:\n",
    "        winner_gt = \"tie\"\n",
    "    winners[winner_gt] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fa4f190d-465c-42ae-8df0-12ceb940bd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.66698706395931"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17312 / 49938 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b47cd35f-7f91-4d2a-b7f0-534084af16da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.012175097120426"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16985 / 49938 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "066e9ee2-6f69-4e7d-94bd-5e85b3f1c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.320837838920262"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15641 / 49938 * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a15d6-4687-4c75-8e85-ade7d16302bb",
   "metadata": {},
   "source": [
    "# 3-way vs 2-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec6ca1b-ab69-46e8-a82d-47ea054ea290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d82d2f84-a1a6-42d7-8d4a-0f90848d16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(file_path):\n",
    "    data = []\n",
    "    # Reading the jsonl file\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            # Parse the line as JSON and add it to the list\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except:\n",
    "                print(line)\n",
    "                raise Exception()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb6dc62-28fe-4db5-b53f-1c77ed192eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat(path):\n",
    "    data = read_jsonl(path)\n",
    "    print(path)\n",
    "    print(\"len:\", len(data))\n",
    "    # 3-way acc\n",
    "    correct, total = 0, 0\n",
    "    for x in data:\n",
    "        if x['winner_gt'] == x['winner_pred']:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    print(\"3-way acc: {:.2f}\".format(correct / total * 100))\n",
    "    \n",
    "    # 2-way acc\n",
    "    correct, total = 0, 0\n",
    "    for x in data:\n",
    "        if x['winner_gt'] == 'tie':\n",
    "            continue\n",
    "        if x['logit_A'] > x['logit_B']:\n",
    "            winner = \"A\"\n",
    "        else:\n",
    "            winner = \"B\"\n",
    "        if winner == x['winner_gt']:\n",
    "            correct += 1\n",
    "        total +=1\n",
    "    print(\"2-way acc: {:.2f}\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e539c49-6101-43c3-8b08-6e6f5546ac24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/Meta-Llama-3-8B.jsonl\n",
      "len: 49938\n",
      "3-way acc: 37.49\n",
      "2-way acc: 55.03\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/Meta-Llama-3-8B.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d5abdd81-7c8d-4098-a8f1-4b451e3411b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/Mistral-7B-Instruct-v0.2.jsonl\n",
      "len: 49938\n",
      "3-way acc: 41.32\n",
      "2-way acc: 59.92\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/Mistral-7B-Instruct-v0.2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ebee9854-8d1b-4c27-967b-0737f929f3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/StableBeluga-7B.jsonl\n",
      "len: 49938\n",
      "3-way acc: 37.77\n",
      "2-way acc: 55.03\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/StableBeluga-7B.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8471b350-cad0-4d6f-a6ff-10d19f209f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/zephyr-7b-beta.jsonl\n",
      "len: 49938\n",
      "3-way acc: 42.11\n",
      "2-way acc: 59.03\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/zephyr-7b-beta.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "eb89a27d-2524-4c70-b6f8-cdceab22aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/Starling-LM-7B-alpha.jsonl\n",
      "len: 49938\n",
      "3-way acc: 45.99\n",
      "2-way acc: 64.35\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/Starling-LM-7B-alpha.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3fc763f0-4f69-4ccd-a830-f03b0636fe77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/Meta-Llama-3-8B-Instruct.jsonl\n",
      "len: 49938\n",
      "3-way acc: 45.34\n",
      "2-way acc: 64.68\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/Meta-Llama-3-8B-Instruct.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "34ea534e-c0f7-4ebe-9976-d3b192f99690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/Mistral-7B-OpenOrca.jsonl\n",
      "len: 49938\n",
      "3-way acc: 43.68\n",
      "2-way acc: 63.31\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/Mistral-7B-OpenOrca.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8f2829ac-aba2-4277-b0f1-2e946d43f4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/dolphin-2.1-mistral-7b.jsonl\n",
      "len: 49938\n",
      "3-way acc: 36.23\n",
      "2-way acc: 53.23\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/dolphin-2.1-mistral-7b.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2edd86dc-f05b-4b22-a9f9-cb503ea39b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/Mistral-7B-Instruct-v0.1.jsonl\n",
      "len: 49938\n",
      "3-way acc: 43.15\n",
      "2-way acc: 62.68\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/Mistral-7B-Instruct-v0.1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a1edac9d-6126-4dc8-935d-40c0be979e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/OpenHermes-2-Mistral-7B.jsonl\n",
      "len: 49938\n",
      "3-way acc: 44.23\n",
      "2-way acc: 63.22\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/OpenHermes-2-Mistral-7B.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3ed5761b-50f0-4954-85e6-996c221ac6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs/lmsys-chatbot-arena-train/OpenHermes-2.5-Mistral-7B.jsonl\n",
      "len: 49938\n",
      "3-way acc: 43.70\n",
      "2-way acc: 61.74\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"outputs/lmsys-chatbot-arena-train/OpenHermes-2.5-Mistral-7B.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af99efc7-3482-4f03-b80d-282f28e09e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/lmsys-chatbot-arena-train/Meta-Llama-3-70B-Instruct.jsonl\n",
      "len: 49938\n",
      "3-way acc: 51.37\n",
      "2-way acc: 70.81\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"../outputs/lmsys-chatbot-arena-train/Meta-Llama-3-70B-Instruct.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "07563e6a-e4e7-45b0-8aa9-26383ea5605c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/lmsys-chatbot-arena-train/Mixtral-8x7B-Instruct-v0.1.jsonl\n",
      "len: 49938\n",
      "3-way acc: 46.72\n",
      "2-way acc: 65.01\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"../outputs/lmsys-chatbot-arena-train/Mixtral-8x7B-Instruct-v0.1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "019c2005-6205-4cb4-a0bc-a711223462e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/lmsys-chatbot-arena-train/Qwen2-72B-Instruct.jsonl\n",
      "len: 49938\n",
      "3-way acc: 52.06\n",
      "2-way acc: 70.66\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"../outputs/lmsys-chatbot-arena-train/Qwen2-72B-Instruct.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d4f0349-f5f2-4474-be05-6c0d35686ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/lmsys-chatbot-arena-train/Hermes-3-Llama-3.1-70B.jsonl\n",
      "len: 49938\n",
      "3-way acc: 50.83\n",
      "2-way acc: 69.52\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"../outputs/lmsys-chatbot-arena-train/Hermes-3-Llama-3.1-70B.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86897fe9-e37c-4f85-af6f-f0517ec5b115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/lmsys-chatbot-arena-train/Athene-70B.jsonl\n",
      "len: 49938\n",
      "3-way acc: 50.04\n",
      "2-way acc: 69.48\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"../outputs/lmsys-chatbot-arena-train/Athene-70B.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d81b1e13-1702-4d7c-b1f0-32ccff0cbfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/lmsys-chatbot-arena-train/dolphin-2.5-mixtral-8x7b.jsonl\n",
      "len: 49938\n",
      "3-way acc: 35.75\n",
      "2-way acc: 52.48\n"
     ]
    }
   ],
   "source": [
    "print_stat(\"../outputs/lmsys-chatbot-arena-train/dolphin-2.5-mixtral-8x7b.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef1378-c7f5-45d0-8f4b-816d615ec5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
